# 保证线上服务稳定

参考资料：
南哥：
https://k1dy9adkxea.feishu.cn/minutes/obcn9b328lhax48oxkkl87m4

## 事前预防服务出问题

对线上环境抱有敬畏之心，每一次操作都要去斟酌是否合理，会不会带来什么问题，只要有问题出现的可能，就要做好应对的措施，可以马上通过手段去恢复线上，将损失降到最低。
写代码时先思考再下手，彻底理解需求，完善设计方案并且要评审（给组内成员或者 leader 评），避免改来改去导致代码失控。
写完代码之后要进行 code review，及时发现隐藏 bug。
制定代码上线的流程规范，开发 -> 自测（开发环境） -> 测试（多套测试环境） -> 验收 -> 上线（生产环境灰度发布） -> 线上验收，确保服务是按照我们想要的动作去运行。
对服务进行压测，了解它的 Qps 极限在哪里，以及 RT、GC 情况（GC 次数、GC 时长）、CPU 利用率、内存情况、网络 IO 情况、日志、报警情况等（由机器去收集以及报警），去感知问题。
主动试探核心功能（mock 数据），更快的感知问题。
尽可能的进行自动化部署，手动参与的环节越少，越不容易出问题（人在重复的劳动中容易犯错，而机器最擅长的就是做重复的劳动）。
做好限流、熔断、降级策略，防止系统某个组件出现故障而导致整个系统崩溃的雪崩效应。
做好容错机制，比如同城容灾、异地多活。
做好监控，使用监控工具实时监控系统运行状况，分析性能瓶颈，提前或者及时做出调整和优化。
针对 QPS 猛增的情况，做好平行扩容，如果是 DDoS 攻击，我们要做好一些防范，如：白名单。
参考资料：
Holis：
https://www.yuque.com/hollis666/hgtuok/vmymwg4epv4o24lc；
https://www.yuque.com/hollis666/hgtuok/gfgqpua8gu3oag44。

## 事中迅速恢复出故障的服务，然后再拿着工具实时收集起来的信息去排查故障原因

恢复故障和排查故障并行，以达到迅速响应的目的。
根据故障紧急预案，针对常见特征问题，进行预设的故障恢复。
如果没有紧急预案，即使十万火急，也要思考清楚再动手，一次性把问题给解决，总比手忙脚乱损失的少。
发挥团队作战优势，让更多的角色来协调工作。

## 事后复盘总结

分析事故的原因。
针对事故原因，完善紧急预案。
对恢复过程进行复盘，分析恢复故障的时间是否满足预期，如果不能，分析该如何去改进或者应对。

## CPU暴涨如何排查

### 查看 CPU 占用情况

top：查看各个进程的 CPU 占用率。
注：shift + p 可以对 CPU 的占用进行排序，然后查看占用 CPU 最大的几个进程看是不是 Java 进程；
注：如果不是 Java 进程，需要报给运维或基础设施部，找他们一起去排查，如 MySQL 连接数太多导致的、Redis 大 key 导致的。
top -Hp PID：查看对应进程的各个线程的 CPU 占用率，得到 CPU 占用率最高的 TID。

### 将 TID 转换为 16 进制

因为在 jstack 日志中，线程 TID 是 16 进制的。

### 输出 Java 进程下各个线程的运行快照到指定文件

jstack PID > /usr/temp/temp.txt

### 查看 jstack 日志

Linux 命令搜索 16 进制的 TID：
tail
cat
less
vi/vim

- CPU 飙高的线程

- 死锁的线程

## 线程死锁

