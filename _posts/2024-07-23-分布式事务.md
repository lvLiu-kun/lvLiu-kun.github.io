# 分布式事务

## XA

利用 MySQL 本地事务特性，两阶段提交（2pc），结合成分布式事务。分布式发起方操作分支事务流程：
try 阶段：
分支事务 begin，然后执行本地事务，此时还没提交。
commit 阶段：
分支事务都确认完之后，进行一个全局的 commit 操作，然后各个分支事务都 commit。
存在问题：
网络分区故障造成的数据不一致：有分支事务没提交成功；
解决方案：三阶段提交（3pc）。
单点故障：整个事务的开始、提交、回滚都是通过 server 端控制；
解决方案：集群。
后面由两阶段提交演进出了三阶段提交，多了避免网络分区故障、默认提交分支事务，分布式发起方操作不同库流程：
pre 阶段：提前测试网络通不通，避免网络故障。
try 阶段。
commit 阶段：try 阶段后分支事务长时间没收到事务提交信息，默认提交（pre 成功了大概率能成功）。
并没有完全解决保证一致性问题，直到 CAP 理论的演进，发现要保证高可用性就没法解决强一致性问题；后面又出现了 BASE 理论。

### 缺点

本地事务一直挂着，占用资源，占用行锁。

### CAP 理论

系统包含 C、A、P 三个要素，并且三者不可兼得，三者只能是CP（强一致性）或者AP（高可用性）。


- 一致性（Consistency）

  各个节点在同一时刻的同一数据是相同的
  
  
- 可用性（Availability）

  系统出错误，但在一定时间范围内仍能够正确响应用户请求
  
  
- 分区容错性（Partition tolerance）

  某节点或网络分区故障时，系统仍能够提供满足一致性和可用性的服务。
  
## Seata AT

Seata AT 是基于两阶段提交的演进，使用 全局锁 + undolog 的方式解决了 XA 协议本地事务一直挂着，占用资源的问题，提高了性能。事务流程如下：
一阶段：
分布式事务发起方向 seata server 端申请全局锁（确保同一时间只有一个分布式事务操作对应的数据），传递给下游的参与服务
分支事务：
开启本地事务
执行本地事务，并生成 seata 自己的undolog到表中（改表根据官网手动创建）
申请全局锁
提交本地事务
二阶段：
提交分布式事务，释放全局锁，删除 seata 对应的undolog。
如果提交分布式事务失败，则回滚所有参与者服务的本地事务，本地事务根据 seata 对应的 undolog 进行反向补偿的更新操作。

为什么不用 tcc 模式？
需要手写接口实现，一但业务复杂，考虑的点很多，繁琐
公司大了，跨部门协调尤其困难。
分支事务为什么不在事务开启时直接申请全局锁？减少锁的时间，提升性能。
隔离级别？读未提交。
全局锁带来的性能问题？分布式事务只能串行执行。

### BASE 理论

不同于 ACID 的强一致性模型，通过牺牲强一致性来获得可用性，并允许数据在同一段时间内是不一致的，但最终达到一致的状态。

- 基本可用（Basically Available）

  分布式系统出现故障时，允许损失部分功能，保证核心功能可用。
  
  
- 软状态（Soft State）

  不同于硬状态，软状态允许系统中的数据存在中间状态，该状态不会影响系统整体的可用性，即允许系统不同节点的数据同步存在延时。
  
- 最终一致性（Eventually Consistent）

  允许系统中的数据在同一段时间内是不一致的，但最终达到一致的状态。
  
  衍生方案：异步、回查、重试
  事务消息（Rocket MQ）
  本地消息表（todo）
  
## tcc

## sega

## RocketMQ事务性消息

最终成功：当上游提交事务性消息到 MQ，如果下游失败了会一直重试，直到成功。

