# RocketMQ

## 选型

为什么选择RocketMQ？
生态好，因为是阿里开源，用的人比较多。
对 Java 开发者更友好，它是用 Java 开发的，自己能看懂；RabbitMQ 是 erlang 写的，没人能看懂。
相比于 kafka，吞吐量高。
kafka 适用于大数据场景，一般用来监听 binlog、数据分析或者日志采集使用；相比于kafka，RocketMQ 更适合 C 端或者互联网的业务场景。
支持事务消息、顺序消息、死信队列的功能。

## 作用

调接口这个东西不可控因素太多了，尤其是对接外部系统，不知道会发生什么（什么时候重启的，什么时候挂的），使用它能换来的性能提升是非常大的，可以允许消息丢失。

### 异步

是针对上游来讲的：当一个服务去同步的去调用另一个服务，另一个服务接口比较缓慢或者宕机了，就会把第一个服务拖垮（阻塞），所以需要一个消息队列去中转，达到一个异步的效果。

注：服务慢可能是要操作数据库、硬件不行等。

### 削峰

是针对下游来讲的：假设一个服务的QPS是100，如果超过了这个上限，其他服务就会把它调挂，通过消息队列，这个服务只需要根据自己的消费速度慢慢从这个队列消费其他服务存放的消息就可以了，达到一个削峰的效果。

### 解耦

是针对整个系统架构来说的：当一个服务依赖多个服务，在这个服务里面写了依赖各种服务的代码，如果其中一个模块发生改变，不管是调用方还是被调用方，都要修改代码，扩展性不好，而通过消息队列，这个服务就不用直接依赖各种服务，只要往这个队列里面发消息，不用关心接收者是谁，被依赖的服务只要去订阅这个队列里的消息就可以了，不用关心消息的来源，到达一个解耦的效果。

### 高可用

是针对整个系统架构来说的：如果消费者宕机了，重启后依旧可以继续执行业务。

## 问题

### 如何保障消息不丢失？

方案：
同步的发送消息
rpc 调用是有网络IO开销的，如果为了提高发送消息的效率，我们一般会做一个异步或者批量的处理，但是这会引起消息丢失。因为如果是异步的方案，发送消息后就直接返回成功了，但是不能保证下游一定是操作成功的，所以会造成消息丢失；批量也是一样的道理，比如我们一次性攒100个请求再发送，假设攒到第99个时服务挂了或重启了，就会造成消息丢失。所以如果为了保障消息不丢失，我们要做消息同步发送，但是发送速度就变慢了。
注：发送方基本的重试机制。
broker 端数据持久化磁盘或者搞主从
因为发送的消息是存在 broker 端的内存里面的（速度快），可能会宕机或者重启，所以会造成消息丢失，如果为了保障消息不丢失，我们可以配置参数，同步的把数据持久化到磁盘，或者搞主从，但是速度就变慢了（那就和调接口没区别了）。
手动 ack，先消费后确认
因为消费者默认是拉到数据直接返回成功，再去处理业务逻辑，不能保障消息是消费成功的，所以会造成消息丢失，如果为了保障消息不丢失，我们可以调换顺序，手动 ack，先消费后确认，但是速度就变慢了。
这都是需要针对不同的业务需求对速度和保障做取舍，而且并没有百分百保证消息不丢失的方法，即使不断堆机器搞主从，机房也都可能烧了。

### 如何解决消息重复消费？

消息幂等：消息被消费很多次，执行的最终结果都一样的。
注：查询、删除是天然的幂等，修改是不变的自然也是幂等，但是修改是有变化的，如 +1 操作，就要做好幂等，以及插入也要做好幂等。
MySQL 唯一索引（插入消息记录表）
Redis分布式锁
重复消息一般来讲是短时间内一条消息同时发了很多次，一般是重试了三四次这种情况，不可能说消息发了之后过了一两个小时又发一条，这种场景很少，所以用 Redis 分布式锁在短时间内做唯一校验就够了（比如订单号），性能比 MySQL 高，用完就释放锁，然后用 MySQL 唯一索引做兜底。

触发原因：成功了就一定成功，失败了不一定失败，可能下游成功了，但是因为异常、弱网（网络超时）、宕机或者重启了，所以没有返回成功。只要消息队列没有给上游生产者返回成功，上游就会一直失败重试（重试机制），以及下游消费者没有 ack 给消息队列，消息队列也会一直失败重试（多次被消费），重试到一定次数，消息就会进入死信队列。

### 如何实现顺序消息？

背景：当消息队列积压消息比较多，一个服务性能有限，消费不过来，这时我们集群，多搞几个服务，提高消费速度。虽然消费者者消费速度提上来了，但是消息队列轮询的给每个消费者消费，比较慢，所以我们对消息队列搞集群，一个 topic 拆分出多个 queue，这里是集群，所以一个 queue 对应一台机器，消费者消费对应 queue 里面的消息，topic 里的消息消费速度就提上来了。但是生产者具体发消息给哪个 queue 是不固定的，所以消息被消费的顺序是不确定的，这就不能保证消息顺序消费，比如先创建订单再付款变成先付款再创建订单，所以，既然不能保证全局顺序，那我们就保证局部顺序，如同一个订单号的消息发往同一个 queue，保证同一个订单号的消息是有序的，消费者单线程的去消费。
注：一个消费者可以消费多个 queue，但一个 queue 不能同时被多个消费者消费。

## 事务性消息原理

事务性消息：保证分布式场景下服务之间的数据一致性（最终一致性）。
正常步骤是这样：
使用@Transactional注解
修改本地数据
发送 mq 消息
修改本地数据和发送 mq 消息的逻辑这样放在一个事务里，是不能保证一致性的。当出现异常时是这样的：
修改本地数据时出现异常，则事务直接回滚，也不会触发发送 mq 消息逻辑；
发送 mq 消息时出现异常，即发送消息失败，则一起回滚。
仔细思考可以发现，发送 mq 消息失败并不代表消息没发送出去，有可能消息队列可能已经接收到消息，只是因为网络抖动而超时，未来得及响应成功；此时发送端本地事务回滚，消息队列接收到了消息并给下游消费了，则造成服务之间的数据不一致。
注：任何 rpc 远程调用都可能出现网络问题，成功了就一定成功，失败了不一定失败。

事务性消息是如何实现最终一致性的？通过两阶段提交思想 +  补偿机制（2PC + 回查）实现，步骤是这样的：
预提交消息：发送 half 半消息到 mq；
注：RocketMQ 里面有一个特殊的队列 half topic，用来暂存事务性消息，对下游是不可见的，half 半消息就是发送到这里。
执行本地事务；
发送真正的提交或回滚消息；
执行本地事务成功，则发送提交信息到 mq，mq 收到消息后就会把存放在 half topic 里面的消息放到真正的 order topic 里面，下游就可以正常消费了；
执行本地事务失败，则发送回滚信息到 mq，mq 将之前的半消息删除。
当出现异常时是这样的：
预提交失败时，会重试一定次数，即使失败了，那么直接回滚，无所谓；
执行本地事务失败时，也是直接回滚；
发送真正的提交或回滚消息失败时，会重试一定次数。
提示：生产者以为自己发送失败了，其实发送成功了，那half 半消息状态会被改变，放到真正的 order topic 里面供消费者正常消费；如果生产者真的发送失败了，half 半消息状态不会被改变，会触发回查机制。
注：RocketMQ 会定期扫描半事务消息，对长期未确认的消息发起主动发起回查（这部分需要我们提供接口给 mq 查询调用，返回值为 true 或 false，告诉它本地事务执行的结果）；默认回查15次，如果15次后仍无法确定结果，RocketMQ默认会删除半消息。

相比于之前的方案，一般本地事务成功了就是成功了，失败了就是失败了，而之前的本地事务成功了，就因为发送 mq 消息失败了而失败了。

提示：和 MySQL 基于 redo log、bin log 的两阶段提交有异曲同工之妙。

扩展：基于本地消息表的最终一致性事务方案。
新建一个任务表，用来记录需要执行的任务；
在本地事务执行时插入一条发送消息的任务记录到任务表；
后续定时任务不断扫表，查询到任务记录后进行消息发送，通过不断异步重试可以做到最终一致性，需要下游做好消息幂等；消费者处理完消息后，给发送消息的那个服务返回确认，收到确认后会把本地消息表对应的记录改为已处理。
注：本地消息表用于实现跨服务或跨系统的最终一致性事务， 每个参与事务的服务都在本地数据库维护了一个消息表，用于记录需要发送的消息以及消息的状态 。

参考资料：
K 哥：
https://yq0pkza686.feishu.cn/wiki/wikcnVAv79gWI2qfBIsRNQFG9Hf

## 视频讲到了订单系统

学了这个项目的时候再回来看下
主单和子单

