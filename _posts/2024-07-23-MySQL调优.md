# MySQL调优

## 架构

### 缓存

使用redis存储常用的数据

- [双写一致性](file:///P:/Redis/myNotes/Redis.xmind)

### 主从

- 读写分离

### 分库分表

分库分表是为了解决单表数据量太大，传统数据库连接数（默认 151）不够，而导致的吞吐量下降的一种手段。
但是分库分表要考虑分表算法、分表字段以及全局 ID 的选择，还会带来跨表查询、跨库事务的问题，不到万不得已再考虑分库分表，可以先考虑数据库的基本优化。

垂直分表：
对字段进行拆分，比如把频繁修改的和不经常修改的字段分开，可以并发效率和查询效率，因为如果不分开，频繁修改一张表一行数据要加载一堆数据，buffer pool 不够用，或者索引失效了，造成全表扫描，这样扫表是很慢的，把数据库干垮了。

示例：
商品（sku）有基础信息表（频繁修改）
			图片信息表（不频繁修改）
			品类信息表（不频繁修改）
			扩展信息表（不频繁修改）
坏处：查询商品信息要多表连接查询或者查询每个表再组装。

水平分表：将一张表的数据拆成多张表存放。
拆分规则：
时间
业务id
订单号后三位的用户id

分表后全局ID如何生成？todo
参考资料：
Holis：https://www.yuque.com/hollis666/hgtuok/glyv4twwk6bfs6dr

## 硬件

### 内存

一般32G，至少16G以上，因为磁盘里的数据是加载到 buff pool里面，buff pool 占数据库的 75 %，如果比较小，加载不了数据页，就会有刷脏页的操作，消耗性能。

### cpu

8核32G、16核32G。

### 硬盘

使用固态硬盘。

## 系统配置

### MySQL版本

MySQL 5.6 支持索引下推。

### MySQL连接数

cpu 核心数 * 2
如果硬盘是固态硬盘 cpu 核心数 * 2 + 1

### 配置刷盘策略

- redolog刷盘策略

	- 0

	  每隔一秒刷
	  
	- 1

	  实时的，每次提交事务都去刷
	  
	- 2

	  由操作系统决定
	  
- binlog刷盘策略

	- 0

	  由系统决定
	  
	  
	- 1

	  每次提交就刷
	  
	- n

	  每提交n个事务刷
	  
	  
	  
## 建表

### 索引

参考资料：
小林 codig：
https://xiaolincoding.com/mysql/index/index_interview.html#%E6%9C%89%E4%BB%80%E4%B9%88%E4%BC%98%E5%8C%96%E7%B4%A2%E5%BC%95%E7%9A%84%E6%96%B9%E6%B3%95

- 主键索引自增

  减少页分裂。
  
- 长字段用前缀索引

- 覆盖索引

  常用字段设置索引，减少回表操作。
  
- hash索引

  表足够散列，就是数据没什么重复，只做等值查询操作，可以用hash索引，查询复杂度O（1）。
  
- 索引最好设置为 NOT NULL

### 日期类型

- datetime 8字节

  显示时间范围大，占用字节大，且与时序无关
  
- timestamp 4字节

  显示日期，时分秒
  
- date 3字节

  显示日期
  
### 尽量用char类型

明确知道数据长度有多长，用char，如手机号，varchar需要维护变长的长度。

### 用数字代表状态

0-“开门” 1-“关门”

- int 4字节

- tinyint 1字节

## [慢SQL](https://lvliu-kun.github.io/2022/07/31/SQL%E4%BC%98%E5%8C%96.html)

开启功能，可以设置阈值（超过多少秒就是慢SQL），还可以设置SQL没走索引记录到慢SQL文件里，可以通过慢SQL文件去查看慢SQL，但是数据库一般是阿里云的，我们可以通过阿里云查看文件

### [select *](https://lvliu-kun.github.io/2022/07/31/SQL%E4%BC%98%E5%8C%96.html#1-%E6%9F%A5%E8%AF%A2sql%E5%B0%BD%E9%87%8F%E4%B8%8D%E8%A6%81%E4%BD%BF%E7%94%A8select-%E8%80%8C%E6%98%AF%E5%85%B7%E4%BD%93%E5%AD%97%E6%AE%B5)

需要什么字段就查什么字段，把所有字段查出来，这样会很慢。

### 多表连接查询

减少多表连接查询，如：
可以不完全按照数据库三范式进行建表，将热点字段冗余；
或将常用和不常用的数据分在两个表上。从而将复杂多表查询变成简单单表查询，提高查询效率。

### 数据量太大

对 sql 执行 explain，查看 sql 执行计划，若没走索引则对关键字段建立索引，加速查询效率。
冷热数据方案。
参考资料：
https://www.bilibili.com/video/BV1N341157rm/?p=31&vd_source=146731dbc824138172a64a7faf714aab

- explain

  输出 sql 语句的执行计划。
  
	- type

		- system

		- const

		  主键索引、唯一索引。
		  
		- eq_ref

		  关联字段是主键或者唯一索引。
		  
		- ref

		  普通索引。
		  
		- range

		  范围查询。
		  
		- index

		  索引覆盖、索引下推。
		  
		- all

		  全表扫描。
		  
### 重复查询同一数据

尤其是慢 SQL，我们可以对数据进行缓存，避免重复查询
如：
用 Redis 对常用的、变化频率不高的、能够接受延迟的数据进行分布式缓存；
以及用 Java 数据结构对接口中多次查询的数据进行本地缓存，如：ArrayList、HashMap，方便下次直接使用；
协定好接口的调用，如果查询过数据了，就通过参数传递过去。

### 深分页查询优化

select * from t where xxx limit 100000, 10;（根据非主键索引去查，要回表）
先定位到具体哪行，再用 limit，如 select * from t where id > 100000 limit 10，前提是这个字段必须是索引且是自增 int 类型。
先用子查询查出 id，减少回表，如 select * from t where xxx and id in (select id from t where xxx limit 100000, 10);

### 分组排序没走索引

尽量走索引

### update没走索引

如果没走索引，rr级别锁表，rc不会，锁表会造成其他事务无法更新，卡着不动，会拖垮服务

### 范围查询不是放到最后

### 批量插入数据一个一个insert

不是一个一个 insert，而是一次 insert 多条数据，默认最多插1g数据。

### 避免索引失效

### 其他

- 硬件配置低

  加大内存：一般32G，至少16G以上，因为磁盘里的数据是加载到buff pool里面，buff pool占数据库的75%，如果比较小，加载不了数据页，就会有刷脏页的操作，消耗性能。
  提高CPU核心数：8核32G、16核32G。
  使用固态硬盘。
  
## 索引

### 索引失效

注：如果连表查询 on 的字段类型不一样，如：一个是 utf-8，一个是Unicode，也会索引失效。

参考资料：
小林 coding：
https://xiaolincoding.com/mysql/index/index_lose.html#%E7%B4%A2%E5%BC%95%E5%A4%B1%E6%95%88%E6%9C%89%E5%93%AA%E4%BA%9B

- 对索引使用左或者左右模糊匹配

- 对索引使用函数

- 对索引进行表达式计算

- 对索引隐式类型转换

  在遇到字符串和数字比较的时候，会自动把字符串转为数字。
  
- [联合索引非最左匹配](https://lvliu-kun.github.io/2024/07/27/%E8%81%94%E5%90%88%E7%B4%A2%E5%BC%95%E5%A4%B1%E6%95%88%E5%88%86%E6%9E%90.html)

- WHERE 子句中的 or

  其中有一个字段没索引，就会全表扫描。
  
## 并发

### 死锁

查看事务情况：select * from information_schema.innodb_trx。
终止事务：kill trx_id。
查看线程情况：show processlist。
查看表使用情况：show OPEN TABLES where In_use > 0，如果表一直锁着，就会 > 0。

解决方案：
隔离级别 rr 降低成 rc。
幻读只是一个现象，并不是一个业务或者技术问题，完全可以放到业务代码逻辑里判断数据要不要使用（一般 C 端业务都是 rc，因为效率高，阿里云 MySQL 默认也是 rc）。
加分布式锁。
分布式环境下，先读再写（先 select for update，再insert），都有并发问题，都要加redis分布式锁（这是一种代码规范）

### update不正确

先把数据查出来放到一个对象，然后再 update 这个对象，并发环境下会造成很严重的后果。

